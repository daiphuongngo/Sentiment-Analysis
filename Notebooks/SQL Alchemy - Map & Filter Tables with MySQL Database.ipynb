{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99bda4f-02f5-47f0-9fb8-011a1616b76d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - SQL Achemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5bac5-9e23-46b5-ac2a-c41715e9d7df",
   "metadata": {},
   "source": [
    "## A. Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2990d8f6-6b72-4d34-bac3-6e24fb994b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sqlalchemy import Column, String, Integer, ForeignKey, DateTime, func\n",
    "from sqlalchemy.orm import relationship, backref\n",
    "from sqlalchemy.ext.declarative import declarative_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf5ec1-156d-4695-b58c-eb56a2e53e40",
   "metadata": {},
   "source": [
    "## B. Load 4 csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1aecf8-04fd-4fa2-ab35-3044254e3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Conversation.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5087e28-b7a3-4be3-b014-e31b2977bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b25909-de7e-42e4-b5aa-9a22ba596b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Information = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Conversation_Information.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c9234-8054-4d60-8b9d-e50ee9ca7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de63dd8c-0a56-4b5e-8c6f-1f836735e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customer = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Customer.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351b14b-e5b1-4fa3-b869-7d28fa276e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d5eb06-dfc9-4367-aac7-f56d7ce52ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fan_Page = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Fan_Page.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802de1e-9a34-40c3-9c8b-0751a994cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Fan_Page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94269532-cd75-448a-996d-761307ad4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Intention = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Conversation_Intention.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f2f78-c6df-4be6-960e-990c8be55a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Intention.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc8be5ec-c3ed-41d1-8519-9095be5518ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Entities = pd.read_csv(\"C:\\Programming\\CustomerIntention\\src\\data\\Conversation_Entities.csv\", encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ffd49-6d55-40ab-b7a3-febccc8f202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Conversation_Entities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3bfe1-82c7-4261-b560-9d950043f960",
   "metadata": {},
   "source": [
    "## Design tables with SQL Alchemy (demo only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df222f-b983-4205-8215-3148a7c262e5",
   "metadata": {},
   "source": [
    "### Import SQL Alchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02667de-94f4-4f67-b631-19b4bc050d10",
   "metadata": {},
   "source": [
    "import sqlalchemy \n",
    "sqlalchemy.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb107c-8745-47fa-ba01-5874ea1d5b78",
   "metadata": {},
   "source": [
    "## C. Create an engine to access the localhost created in the Command Prompt run as administrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b484ba56-472d-4738-92db-c67ac7dd344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4', echo=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083c9f6-0764-409c-a6dd-c841a8140831",
   "metadata": {},
   "source": [
    "## D. Design 6 tables 'Conversation', 'Conversation_Information', 'Customer', 'Fan_Page', 'Conversation_Intention', 'Conversation_Entities'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaaeaf0-f4db-449f-8719-4523491a5393",
   "metadata": {},
   "source": [
    "For reference of other methods of DataTime only:\n",
    "https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ac234-3c82-4b95-9c7f-88bb3a65c576",
   "metadata": {},
   "source": [
    "Now let's execute this cell to start creating tables for TablePlus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb832501-cdbe-449a-bbc6-706863fbf314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, String, Integer, ForeignKey, DateTime, func, Boolean, MetaData, Table, Float\n",
    "from sqlalchemy.dialects.mysql import TINYINT\n",
    "from sqlalchemy.orm import relationship, backref\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base() \n",
    "metadata = MetaData(bind=engine) \n",
    "\n",
    "class Conversation(Base):\n",
    "    __tablename__ = Table('conversation', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine) # metadata comes from database\n",
    "    # Database (TablePlus) will regularize PK, Python won't do so (primary_key=True) since this is for mapping tables only. \n",
    "    # If Python is used for creating tables, we will need ID as a PK so 'primary_key=True' will be included.\n",
    "    id = Column(Integer, primary_key=True) \n",
    "    conversation_id = Column(Integer)\n",
    "    message = Column(String())\n",
    "    order = Column(Integer) # must have data type, Integer doesn't need to have Integer(8)\n",
    "    sender = Column(Integer) \n",
    "    fan_page_id = Column(Integer)\n",
    "    cus_id = Column(Integer)\n",
    "    \n",
    "class Conversation_Information(Base):\n",
    "    __tablename__ = Table('conversation_information', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine) \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    conversation_id = Column(Integer)\n",
    "    customer_count = Column(Integer)\n",
    "    sales_count = Column(Integer)\n",
    "    start_time = Column(\n",
    "        DateTime(timezone=True)) # https://stackoverflow.com/questions/13370317/sqlalchemy-default-datetime\n",
    "    end_time = Column(\n",
    "        DateTime(timezone=True))\n",
    "    \n",
    "class Customer(Base):\n",
    "    __tablename__ = Table('customer', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine)\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    cus_name = Column(String)\n",
    "    cus_id = Column(Integer) # must not fix structure of the database here\n",
    "    \n",
    "class Fan_Page(Base):\n",
    "    __tablename__ = Table('fan_page', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine)\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    fan_page_name = Column(String)\n",
    "    fan_page_id = Column(Integer)\n",
    "    \n",
    "class Conversation_Intention(Base):\n",
    "    __tablename__ = Table('conversation_intention', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine)\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    conversation_id = Column(Integer)\n",
    "    intention_label = Column(String)\n",
    "    intention_score = Column(Float)\n",
    "    \n",
    "class Conversation_Entities(Base):\n",
    "    __tablename__ = Table('conversation_entities', Base.metadata,\n",
    "                    autoload=True, autoload_with=engine)\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    conversation_id = Column(Integer)\n",
    "    conversation_entity = Column(String)\n",
    "    conversation_entity_score = Column(Float)\n",
    "    conversation_entity_word = Column(String)\n",
    "    \n",
    "# Mapping classes with tables in TablePlus's databases\n",
    "# Should not create tables by Python but TablePlus\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "#Session = sessionmaker()\n",
    "#Session.configure(bind=engine)\n",
    "Session = sessionmaker(bind=engine) # writing queries requires session before executing queries\n",
    "session = Session() # object\n",
    "#Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26aaba3-ef87-4025-802d-d90086bb5424",
   "metadata": {},
   "source": [
    "### Print the current row of each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "800abc5c-e7a4-4bf3-a9a5-74df958f60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x20293831100>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_results = session.query(Conversation)\n",
    "conversation_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46788ad-865f-4abf-b881-bac95cd354b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation in conversation_results: # each item of the object\n",
    "    print(conversation.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2551220-5e37-460e-94c0-046152e278a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x20277b926a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_information_results = session.query(Conversation_Information)\n",
    "conversation_information_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cb79f-b9cd-402c-be4b-2ad0de1046c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation_information in conversation_information_results: \n",
    "    print(conversation_information.customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "072fe0a0-b0d7-4553-8cd3-e15a213c2052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x214be973550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_results = session.query(Customer)\n",
    "customer_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3519cdf-2bf1-4101-8882-5762e357a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer in customer_results:\n",
    "    print(customer.cus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c0c333d-7de2-4390-b1bf-aab49222d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x20293825400>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_page_results = session.query(Fan_Page)\n",
    "fan_page_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b802c-f692-4829-95fd-f6d56cd7ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fan_page in fan_page_results: \n",
    "    print(fan_page.fan_page_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce098a8-332a-4dc3-bf8c-913e803cc820",
   "metadata": {},
   "source": [
    "### Add new row(s) to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0a767-61f4-44b0-bdd0-b685eaa3d220",
   "metadata": {},
   "source": [
    "https://docs.sqlalchemy.org/en/14/tutorial/data_insert.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34b642-3060-43df-bf94-89e84db092fc",
   "metadata": {},
   "source": [
    "ID is set as Primary Key which is auto-increment in TablePlus so I will not try to add a new row having ID in this code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1c7d3488-0037-41f8-be99-bb554fce79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15 00:56:40,618 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2021-09-15 00:56:40,624 INFO sqlalchemy.engine.Engine INSERT INTO conversation (message, `order`, sender) VALUES (%s, %s, %s)\n",
      "2021-09-15 00:56:40,625 INFO sqlalchemy.engine.Engine [generated in 0.00196s] ('Could I ask you something?', '0', '0')\n",
      "2021-09-15 00:56:40,633 INFO sqlalchemy.engine.Engine INSERT INTO conversation_information (conversation_id, customer_count, sales_count, start_time, end_time) VALUES (%s, %s, %s, now(), now())\n",
      "2021-09-15 00:56:40,634 INFO sqlalchemy.engine.Engine [generated in 0.00101s] ('1', '1', '0')\n",
      "2021-09-15 00:56:40,639 INFO sqlalchemy.engine.Engine INSERT INTO customer (cus_name, cus_id) VALUES (%s, %s)\n",
      "2021-09-15 00:56:40,640 INFO sqlalchemy.engine.Engine [cached since 7943s ago] ('Frank', '3')\n",
      "2021-09-15 00:56:40,644 INFO sqlalchemy.engine.Engine INSERT INTO fan_page (fan_page_name, fan_page_id) VALUES (%s, %s)\n",
      "2021-09-15 00:56:40,645 INFO sqlalchemy.engine.Engine [generated in 0.00151s] ('DEF', '2')\n",
      "2021-09-15 00:56:40,654 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    newConversation = Conversation(\n",
    "        message = 'Could I ask you something?',\n",
    "        order = '0',\n",
    "        sender = '0'\n",
    "    )\n",
    "    session.add(newConversation)\n",
    "        \n",
    "    newConversationInformation = Conversation_Information(\n",
    "        conversation_id = '1',\n",
    "        customer_count = '1',\n",
    "        sales_count = '0'\n",
    "    )\n",
    "    session.add(newConversationInformation)\n",
    "    \n",
    "    newCustomer = Customer(\n",
    "        cus_name = 'Frank',\n",
    "        cus_id = '3'\n",
    "    )\n",
    "    session.add(newCustomer)\n",
    "    \n",
    "    newFanPage = Fan_Page(\n",
    "        fan_page_name = 'DEF',\n",
    "        fan_page_id = '2'\n",
    "    )\n",
    "    session.add(newFanPage)\n",
    "    \n",
    "    session.commit() # commit once only\n",
    "except:\n",
    "    session.rollback() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea7feb-ee78-49de-b984-16bc14403d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:     \n",
    "    newConversationInformation = Conversation_Information(\n",
    "        conversation_id = '2',\n",
    "        customer_count = '2',\n",
    "        sales_count = '2'\n",
    "    )\n",
    "    session.add(newConversationInformation)\n",
    "    \n",
    "    session.commit() # commit once only\n",
    "except:\n",
    "    session.rollback() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a518663-1ce2-4ca6-876c-d484af6bc42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4024005, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Conversation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f1f69-ced6-463b-9ff6-e2f2056cf304",
   "metadata": {},
   "source": [
    "### Print them out again to see the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e30c1e8e-6e86-4e81-97b7-08ef40e68982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x25afa969a90>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_results = session.query(Customer)\n",
    "customer_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6eb99-5336-4d14-953b-be79c9336728",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation in conversation_results:\n",
    "    print(conversation.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e153c15b-af92-4027-83e7-7079ba929338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x25afa9694f0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_information_results = session.query(Conversation_Information)\n",
    "conversation_information_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab6cd6-61a9-484e-814b-e74609804e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation_information in conversation_information_results:\n",
    "    print(conversation_information.customer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a63b2c8-1b0a-4468-9448-72a60f7303d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x20277ba6df0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_results = session.query(Customer)\n",
    "customer_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef831e-e27d-4b73-81e2-7b853313afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer in customer_results: \n",
    "    print(customer.cus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e0861f0-5c3e-49e4-8d19-086303642d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x25afa969460>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_page_results = session.query(Fan_Page)\n",
    "fan_page_results #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7d7a1-6b29-490e-bfbb-0bebc9332848",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fan_page in fan_page_results: \n",
    "    print(fan_page.fan_page_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b07dd8-f159-465c-b846-d50cadf02295",
   "metadata": {},
   "source": [
    "## E. Insert all rows of each dataframe to database's tables in TablePlus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdd4af-ac58-49db-95cd-6e84e5ec1641",
   "metadata": {},
   "source": [
    "New Method: inserting directly from data frames\n",
    "\n",
    "Inserting takes long time means that selecting or filtering will take less time, and in reverse, due to adding IDX for a column or different columns depending on purposes of saving data into relational database only or reading the data.\n",
    "\n",
    "We will insert dataframes in batches into session (relational database), then commit to finalize saving. If an error happen, that batch will be stopped inserting and still stay in the session and other batches will not be entered into the session as well if flush() is placed outside 'for loop'. Therefore, if flush() is placed inside the for loop, batches will be flushed into the session regarless any error might occur. But we have to set rollback() in the except case to delete any existing batches in the session causing an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16966b84-1d45-438c-bf26-d00b39f383af",
   "metadata": {},
   "source": [
    "### Insert 'df_Conversation' dataframe into 'conversation' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da12598-382b-46a5-ae6e-ac304d4c998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import unicodedata \n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "\n",
    "def conversation_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # Index column must match with ID column of df_Conversation  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            conversation = Conversation()\n",
    "            conversation.order = df_Conversation['Order'].iloc[i]\n",
    "            conversation.sender = df_Conversation['Sender'].iloc[i]\n",
    "            conversation.message = unicodedata.normalize('NFC', str(df_Conversation['Message'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\"))\n",
    "            conversation.fan_page_id = int(df_Conversation['Fanpage'].iloc[i]) # recreate the DB\n",
    "            conversation.cus_id = df_Conversation['PSID'].iloc[i] \n",
    "            DBSession.add(conversation) # error might happen here or below\n",
    "            DBSession.commit()\n",
    "            \n",
    "            if i % 1000 == 0: # when i reachs 1000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "                #text = unicodedata.normalize('NFC', text) # text: string type to fix error and replace all string texts into being wrapped by unicode \n",
    "                \n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "   # DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Conversation's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #conversation_sqlalchemy_orm(df_Conversation.shape[0]) # number of rows of df as I want --> customized function name\n",
    "    conversation_sqlalchemy_orm(df_Conversation.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec2798-7104-4a87-a51b-b7b7dab8bb1f",
   "metadata": {},
   "source": [
    "### Insert 'df_Conversation_Information' dataframe into 'conversation_information' database\n",
    "\n",
    "There will be an Error at index 260000 due to Duplicate entry '250001' for key 'IDX_conversation_id' so I have to delete this IDX of Conversation ID in the MYSQL by creating a new table for Conversation there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7242d65-0b38-4fa4-8706-2628aa580d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████▏           | 263006/314543 [05:06<00:12, 4210.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at index 260000: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1771, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\cursors.py\", line 206, in execute\n",
      "    res = self._query(query)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\cursors.py\", line 319, in _query\n",
      "    db.query(q)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\connections.py\", line 259, in query\n",
      "    _mysql.connection.query(self, query)\n",
      "MySQLdb._exceptions.IntegrityError: (1062, \"Duplicate entry '250001' for key 'IDX_conversation_id'\")\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_14852/1345421764.py\", line 37, in conversation_information_sqlalchemy_orm\n",
      "    DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
      "  File \"<string>\", line 2, in flush\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 3298, in flush\n",
      "    self._flush(objects)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 3438, in _flush\n",
      "    transaction.rollback(_capture_exception=True)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\", line 70, in __exit__\n",
      "    compat.raise_(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\util\\compat.py\", line 207, in raise_\n",
      "    raise exception\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 3398, in _flush\n",
      "    flush_context.execute()\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py\", line 456, in execute\n",
      "    rec.execute(self)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py\", line 630, in execute\n",
      "    util.preloaded.orm_persistence.save_obj(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\persistence.py\", line 242, in save_obj\n",
      "    _emit_insert_statements(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\orm\\persistence.py\", line 1219, in _emit_insert_statements\n",
      "    result = connection._execute_20(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1583, in _execute_20\n",
      "    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 323, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1452, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1814, in _execute_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1995, in _handle_dbapi_exception\n",
      "    util.raise_(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\util\\compat.py\", line 207, in raise_\n",
      "    raise exception\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1771, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\cursors.py\", line 206, in execute\n",
      "    res = self._query(query)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\cursors.py\", line 319, in _query\n",
      "    db.query(q)\n",
      "  File \"C:\\Programming\\CustomerIntention\\venv\\lib\\site-packages\\MySQLdb\\connections.py\", line 259, in query\n",
      "    _mysql.connection.query(self, query)\n",
      "sqlalchemy.exc.IntegrityError: (MySQLdb._exceptions.IntegrityError) (1062, \"Duplicate entry '250001' for key 'IDX_conversation_id'\")\n",
      "[SQL: INSERT INTO conversation_information (conversation_id, customer_count, sales_count, start_time, end_time) VALUES (%s, %s, %s, %s, %s)]\n",
      "[parameters: (250001, 1, 2, '2020-02-13 09:53:04.000', '2020-07-10 05:15:24.000')]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n",
      "\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 314543/314543 [06:07<00:00, 856.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation_Information's SQLAlchemy ORM: Total time for 314543 records 367.33158469200134 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "\n",
    "def conversation_information_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # Index column must match with ID column of df_Conversation  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            conversation_information = Conversation_Information()\n",
    "            conversation_information.conversation_id = df_Conversation_Information['Conversation_ID'].iloc[i]\n",
    "            conversation_information.customer_count = df_Conversation_Information['CustomerCount'].iloc[i]\n",
    "            conversation_information.sales_count = df_Conversation_Information['SalesCount'].iloc[i]\n",
    "            conversation_information.start_time = df_Conversation_Information['StartTime'].iloc[i] # google, insert 1 row only for trial\n",
    "            conversation_information.end_time = df_Conversation_Information['EndTime'].iloc[i]\n",
    "            \n",
    "            DBSession.add(conversation_information) # error might happen here or below\n",
    "            if i % 10000 == 0: # when i reachs 1000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "   # DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Conversation_Information's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conversation_information_sqlalchemy_orm(df_Conversation_Information.shape[0]) # number of rows of df as I want --> customized function name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b527fac-b843-419d-b777-8ab71e99e1c5",
   "metadata": {},
   "source": [
    "### Insert 'df_Fan_Page' dataframe into 'fan_page' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04735011-c08e-45ce-90c7-94d034b3a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 314543/314543 [05:56<00:00, 883.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fan_Page's SQLAlchemy ORM: Total time for 314543 records 356.1085169315338 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import unicodedata \n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "def fan_page_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # Index column must match with ID column of df_Conversation  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            fan_page = Fan_Page()\n",
    "            fan_page.fan_page_name = unicodedata.normalize('NFC', str(df_Fan_Page['FanpageName'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\"))\n",
    "            fan_page.fan_page_id = df_Fan_Page['Fanpage'].iloc[i]\n",
    "            #fan_page.start_time = df_Fan_Page['StartTime'].iloc[i] # google, insert 1 row only for trial\n",
    "            #fan_page.end_time =  df_Fan_Page['EndTime'].iloc[i]\n",
    "            \n",
    "            DBSession.add(fan_page) # error might happen here or below\n",
    "            if i % 10000 == 0: # when i reachs 1000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "   # DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Fan_Page's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fan_page_sqlalchemy_orm(df_Fan_Page.shape[0]) # number of rows of df as I want --> customized function name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e171e1-ee4f-4b04-9142-37c233bce41c",
   "metadata": {},
   "source": [
    "### Insert 'df_Customer' dataframe into 'customer' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dad3923a-f632-43df-bdae-f4f76ac0ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 314543/314543 [37:00<00:00, 141.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer's SQLAlchemy ORM: Total time for 314543 records 2220.204922914505 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import unicodedata \n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "\n",
    "def customer_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # index column must match with ID column of df_Customer  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            customer = Customer()\n",
    "            customer.cus_name = unicodedata.normalize('NFC', str(df_Customer['CusName'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\")) # Use rows from dataframe to insert them into the relational databse, not insert the self-created rows\n",
    "            #customer.cus_name = df_Customer['CusName'].iloc[i]\n",
    "            customer.cus_id = df_Customer['PSID'].iloc[i]\n",
    "            DBSession.add(customer) # error might happen here or below\n",
    "            DBSession.commit()\n",
    "            if i % 10000 == 0: # when i reachs 10000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "    #DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Customer's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #customer_sqlalchemy_orm(df_Customer.shape[0]) # number of rows of df as I want --> customized function name\n",
    "    customer_sqlalchemy_orm(df_Customer.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958836e-d6af-4a39-b805-7aeab6a43fbf",
   "metadata": {},
   "source": [
    "### Insert 'Conversation_Intention' dataframe into 'conversation_intention' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70e4e5-7e9d-453c-9974-b4c681eb7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import unicodedata \n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "def conversation_intention_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # Index column must match with ID column of df_Conversation  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            conversation_intention = Conversation_Intention()\n",
    "            conversation_intention.reference_id = df_Conversation_Intention['Conversation_ID'].iloc[i]\n",
    "            conversation_intention.intention_label = unicodedata.normalize('NFC', str(df_Conversation_Intention['Intention_Label'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\"))\n",
    "            conversation_intention.intention_score = df_Conversation_Intention['Fanpage'].iloc[i]\n",
    "            \n",
    "            DBSession.add(conversation_intention) # error might happen here or below\n",
    "            if i % 10000 == 0: # when i reachs 1000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "   # DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Conversation_Intention's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conversation_intention_sqlalchemy_orm(df_Conversation_Intention.shape[0]) # number of rows of df as I want --> customized function name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baeb85b-1b66-4ae7-b0b1-6ff02c4c56a8",
   "metadata": {},
   "source": [
    "### Insert 'Conversation_Entities' dataframe into 'conversation_entities' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c7c2f-9925-4981-bce2-c527fc731829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import mysql.connector # as below mysql, not sqlite3 for this case\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String,  create_engine # use sqlalchemy with connection string for mysql\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "import unicodedata \n",
    "\n",
    "Base = declarative_base()\n",
    "DBSession = scoped_session(sessionmaker()) # the scoped_session() function is provided which produces a thread-managed registry of Session objects. It is commonly used in web applications so that a single global variable can be used to safely represent transactional sessions with sets of objects, localized to a single thread.\n",
    "engine = None\n",
    "\n",
    "def init_sqlalchemy(dbname='mysql+mysqldb://phuongdaingo:0505@localhost:3306/customerintention?charset=utf8mb4'):\n",
    "    global engine\n",
    "    engine = create_engine(dbname, echo=False)\n",
    "    DBSession.remove()\n",
    "    DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)\n",
    "    Base.metadata.drop_all(engine)\n",
    "    Base.metadata.create_all(engine)\n",
    "    \n",
    "def conversation_entities_sqlalchemy_orm(n=100000): \n",
    "    init_sqlalchemy()\n",
    "    t0 = time.time() \n",
    "    error_i_list = [] # a new list containing i(s) of batch(es) causing errors\n",
    "    # Index column must match with ID column of df_Conversation  > indexing to the row 10th iso using loop with iterows (time consuming), but by using range(df.rows) > take out the 10th row\n",
    "    for i in tqdm(range(n)): # use tqdm to track progress \n",
    "        try: # create custome, then add into session\n",
    "            conversation_entities = Conversation_Entities()\n",
    "            conversation_entities.reference_id = df_Conversation_Entities['Conversation_ID'].iloc[i]\n",
    "            conversation_entities.conversation_entity = unicodedata.normalize('NFC', str(df_Conversation_Entities['Conversation_Entity'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\"))\n",
    "            conversation_entities.conversation_entity_score = df_Conversation_Entities['Conversation_Entity_Score'].iloc[i]\n",
    "            conversation_entities.conversation_entity_word = unicodedata.normalize('NFC', str(df_Conversation_Entities['Conversation_Entity_word'].iloc[i]).encode(\"utf-8\").decode(\"utf-8\"))\n",
    "\n",
    "            \n",
    "            DBSession.add(conversation_entities) # error might happen here or below\n",
    "            if i % 10000 == 0: # when i reachs 1000 rows, it will execute by flush() to insert the batch of 1000 rows into the session of the relational database\n",
    "                DBSession.flush() # should use try, except inside each 'for loop' to wrap i # error might happen here\n",
    "                DBSession.commit() #2nd attempt: place commit() here, then compare the progress # commit here to insert batch without affecting other batch(es) with errors\n",
    "        except Exception as er:\n",
    "            print('Error at index {}: '.format(i))\n",
    "            print(traceback.format_exc()) # print error(s)\n",
    "            print('-' * 20)\n",
    "            DBSession.rollback() # rollback here to delete all rows of a batch/batches causing errors to avoid being flooded or stuck with new batches coming in and then getting stuck as well\n",
    "            error_i_list.append(i) # append into array the index of batch(es) causing errors \n",
    "   # DBSession.commit()  # 1st attempt: place commit() here, outside of 'for loop' # faster but will stop other batches coming in if errors happen\n",
    "    \n",
    "    print(\n",
    "        \"Conversation_Entities's SQLAlchemy ORM: Total time for \" + str(n) +\n",
    "        \" records \" + str(time.time() - t0) + \" secs\")\n",
    "\n",
    "    # A new function to select rows from conversations with a condition filtering by cus_id, joining with table 'customer' to return the cus_name\n",
    "#def join_tables():\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conversation_entities_sqlalchemy_orm(df_Conversation_Entities.shape[0]) # number of rows of df as I want --> customized function name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9671585-f096-4433-8541-16be6199e452",
   "metadata": {},
   "source": [
    "## F. Select, Filter - Using query on session with joining method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100004e-3d53-41b3-888c-9e61ab95cb95",
   "metadata": {},
   "source": [
    "https://www.tutorialspoint.com/sqlalchemy/sqlalchemy_orm_working_with_joins.htm\n",
    "\n",
    "https://docs.sqlalchemy.org/en/14/orm/query.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de261f-4893-4e83-b6d8-5618c148d0d2",
   "metadata": {},
   "source": [
    "### Filter the Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d4dd2-5b0e-4370-9310-8badd350eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Conversation).filter(Conversation.order == 0).all() #first(): get the first or all(): get all\n",
    "for val in stmt:\n",
    "    print(val.message)\n",
    "    print(val.order)\n",
    "    print(val.sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfd0a0-b49b-4577-bea4-05ee70bc9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_Conversation = session.query(Conversation).join(Fan_Page.fan_page_id).filter(Conversation.order == 0).all() #first(): get the first or all(): get all\n",
    "for val in stmt_Conversation:\n",
    "    print(val.message)\n",
    "    print(val.order)\n",
    "    print(val.sender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde524f4-253a-4d3f-8115-8fe28fca56e3",
   "metadata": {},
   "source": [
    "### Filter the Conversation_Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64f054-535f-4c4c-baa5-a86ecfed073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Conversation_Information).filter(Conversation_Information.conversation_id == 0).first() #first(): get the first or all(): get all\n",
    "#for val in stmt:\n",
    "    #print(val.conversation_id)\n",
    "    #print(val.customer_count)\n",
    "    #print(val.sales_count)\n",
    "print(stmt.conversation_id)\n",
    "print(stmt.customer_count)\n",
    "print(stmt.sales_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceac1df-3cc8-4a66-b323-8bc0bafd039e",
   "metadata": {},
   "source": [
    "Reference: https://stackoverflow.com/questions/51451768/sqlalchemy-querying-with-datetime-columns-to-filter-by-month-day-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00192f2-b1a0-43d7-a2fa-afda4a4b0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Conversation_Information).filter(Conversation_Information.start_time == '2019-11-03'\n",
    "                                                     ).all() #first(): get the first or all(): get all\n",
    "#for val in stmt:\n",
    "    #print(val.conversation_id)\n",
    "    #print(val.customer_count)\n",
    "    #print(val.sales_count)\n",
    "print(stmt.conversation_id)\n",
    "print(stmt.customer_count)\n",
    "print(stmt.sales_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdb79f-e15a-434b-8bff-b13fe2e6f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_Conversation_Info = session.query(Conversation_Information).join(Conversation.id).limit(5).filter(Conversation_Information.conversation_id == 0).all() #first(): get the first or all(): get all\n",
    "for val in stmt_Conversation_Info:\n",
    "    print(val.conversation_id)\n",
    "    print(val.customer_count)\n",
    "    print(val.sales_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106c61e-2477-4bb6-91e0-498d9f90874f",
   "metadata": {},
   "source": [
    "### Filter the Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d44a2c-4e6f-404d-b85d-116ae8900a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Customer).filter(Customer.cus_name == 'Simon').first() #first(): get the first or all(): get all\n",
    "print(stmt.cus_id)\n",
    "print(stmt.cus_name)\n",
    "print(stmt.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d2388-d47c-412f-b75d-2c4650622fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_Customer_name(name)\n",
    "    stmt = session.query(Customer).filter(Customer.cus_name == name).first() #first(): get the first or all(): get all\n",
    "    for val in stmt:\n",
    "        print(val.cus_id)\n",
    "        print(val.cus_name)\n",
    "        print(val.id)\n",
    "filter_Customer_name('Tòng thị tươi thuý')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146052a6-4162-4c93-a485-c550a82f4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_Customer = session.query(Customer).join(Conversation.id).filter(Customer.cus_name == 'Simon').first() #first(): get the first or all(): get all\n",
    "for val in stmt_Customer:\n",
    "    print(val.cus_id)\n",
    "    print(val.cus_name)\n",
    "    print(val.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315047ea-a4d1-4a73-9d1f-34f5329b6bcc",
   "metadata": {},
   "source": [
    "### Filter the Fan_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee68c5a-54ed-4dd0-af94-ee1776649a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Fan_Page).filter(Fan_Page.fan_page_name == 'Simon').all() #first(): get the first or all(): get all\n",
    "for val in stmt:\n",
    "    print(val.fan_page_name)\n",
    "    print(val.fan_page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1207c-d33b-480b-b005-d67789f75a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_Fan_Page_name(name)    \n",
    "    stmt = session.query(Fan_Page).filter(Fan_Page.fan_page_name == name).all() #first(): get the first or all(): get all\n",
    "    for val in stmt:\n",
    "        print(val.fan_page_name)\n",
    "        print(val.fan_page_id)\n",
    "filter_Fan_Page_name('Hân Beauty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c1a95-c41b-41d7-9cdf-8d87edf6f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_Fan_Page = session.query(Fan_Page).filter(Fan_Page.fan_page_name == 'Simon').all() #first(): get the first or all(): get all\n",
    "for val in stmt_Fan_Page:\n",
    "    print(val.fan_page_name)\n",
    "    print(val.fan_page_id)\n",
    "    print(val.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535f3f4-6f26-4d8e-b26a-2b2b75bbcb28",
   "metadata": {},
   "source": [
    "## G. Select, Filter with data directly created in the MySQL Relational Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747bc27-9cf1-4d45-9815-efdbb8d14730",
   "metadata": {},
   "source": [
    "### Filter by query Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d3cd0-e49e-48b6-9763-1d10bcc5850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Conversation).filter(Conversation.order == 0).all() #first(): get the first or all(): get all\n",
    "for val in stmt:\n",
    "    print(val.message)\n",
    "    print(val.order)\n",
    "    print(val.sender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf0ca9-5188-475b-ba8a-4d7b4f0abdb3",
   "metadata": {},
   "source": [
    "### Filter by query Conversation_Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184194d-3537-48e4-98c0-3fc4e0a23cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Conversation_Information).filter(Conversation_Information.conversation_id == 0).first() #first(): get the first or all(): get all\n",
    "#for val in stmt:\n",
    "    #print(val.conversation_id)\n",
    "    #print(val.customer_count)\n",
    "    #print(val.sales_count)\n",
    "print(stmt.conversation_id)\n",
    "print(stmt.customer_count)\n",
    "print(stmt.sales_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd5426-cd12-464a-b5e9-5f9018973838",
   "metadata": {},
   "source": [
    "### Filter by query Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e22726-62ba-46aa-b533-da129a3a9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Customer).filter(Customer.cus_name == 'Frank').first() #first(): get the first or all(): get all\n",
    "print(stmt.cus_id)\n",
    "print(stmt.cus_name)\n",
    "print(stmt.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00335e6-6247-47cb-969f-ba2e7b55192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Customer).filter(Customer.cus_id % 2 == 0).all()\n",
    "for val in stmt:\n",
    "    print(val.cus_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f338d0-529b-4159-b1d5-5ea5730c5990",
   "metadata": {},
   "source": [
    "### Filter by query Fan_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546d957-49b9-48e2-a6a6-afb555f753d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = session.query(Fan_Page).filter(Fan_Page.fan_page_name == 'ABC').all() #first(): get the first or all(): get all\n",
    "for val in stmt:\n",
    "    print(val.fan_page_name)\n",
    "    print(val.fan_page_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
